{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Cargar imágenes desde directorio\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data',\n",
    "    image_size=(128, 128),  # Tamaño al que se redimensionan las imágenes\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'  # Cambiar a 'int' si necesitas etiquetas como enteros\n",
    ")\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "train_ds = dataset.take(int(0.8 * len(dataset)))\n",
    "val_ds = dataset.skip(int(0.8 * len(dataset)))\n",
    "\n",
    "# Normalizar imágenes\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 64, 64, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 32, 32, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 16, 16, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 8, 8, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8778562 (33.49 MB)\n",
      "Trainable params: 8778562 (33.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "17/17 [==============================] - 37s 2s/step - loss: 0.4712 - accuracy: 0.8382 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0684 - accuracy: 0.9798 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 0.0063 - val_accuracy: 0.9936\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 2.4459e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "5/5 [==============================] - 3s 358ms/step - loss: 3.2323e-06 - accuracy: 1.0000\n",
      "Loss: 0.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, GlobalAveragePooling2D\n",
    "\n",
    "# Entrada de la imagen\n",
    "input_image = Input(shape=(128, 128, 3))\n",
    "\n",
    "# Primera capa convolucional (similar a las primeras capas de YOLO)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_image)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Segunda capa convolucional\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Tercera capa convolucional\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Cuarta capa convolucional (aumentando la profundidad de la red)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Capa de aplanado\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Capa densa\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Capa final para clasificación, usando softmax para clases múltiples\n",
    "output = Dense(train_ds.element_spec[1].shape[1], activation='softmax')(x)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs=input_image, outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,  # Puedes ajustar el número de épocas\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('modelo_yolov8_inspirado.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
